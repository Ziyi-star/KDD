{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede66d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\\rtf1\\ansi\\ansicpg1252\\cocoartf2639\n",
    "\\cocoatextscaling0\\cocoaplatform0{\\fonttbl\\f0\\fswiss\\fcharset0 Helvetica;}\n",
    "{\\colortbl;\\red255\\green255\\blue255;}\n",
    "{\\*\\expandedcolortbl;;}\n",
    "\\paperw11900\\paperh16840\\margl1440\\margr1440\\vieww11520\\viewh8400\\viewkind0\n",
    "\\pard\\tx566\\tx1133\\tx1700\\tx2267\\tx2834\\tx3401\\tx3968\\tx4535\\tx5102\\tx5669\\tx6236\\tx6803\\pardirnatural\\partightenfactor0\n",
    "\n",
    "\\f0\\fs24 \\cf0 import math\\\n",
    "from collections import Counter, defaultdict\\\n",
    "import numpy as np\\\n",
    "import random # Just needed for 6ECTS\\\n",
    "\\\n",
    "\\\n",
    "def euclidean_dist(x, y):\\\n",
    "    xnp = np.array(x)\\\n",
    "    ynp = np.array(y)\\\n",
    "    #print ('xnp, ynp', xnp, ynp)\\\n",
    "    return np.linalg.norm(ynp-xnp)\\\n",
    "\\\n",
    "def split(X, Y, n=5):\\\n",
    "    \"Split the training points and labels into 5 equal sized parts. Just needed for 6 ECTS.\"\\\n",
    "    m = list(range(len(X)))\\\n",
    "    X = np.array(X)\\\n",
    "    Y = np.array(Y)\\\n",
    "    indices = [np.array(m[i::n]) for i in range(n)]\\\n",
    "    X = [X[i].tolist() for i in indices]\\\n",
    "    Y = [Y[i].tolist() for i in indices]\\\n",
    "    return X, Y\\\n",
    "\\\n",
    "class KNN():\\\n",
    "    def __init__(self, dist_fun=euclidean_dist):\\\n",
    "        self.dist_fun = dist_fun\\\n",
    "        self.strategies = ['majority', 'inverse_squared_distance', 'inverse_avg_distance', 'distribution']\\\n",
    "    \\\n",
    "    def train(self, X, Y, ks=None):\\\n",
    "        \"\"\" Train this classifier. Takes a list of samples X and a list of class-labels Y.\\\n",
    "        Each sample is a list of numeric values. Each label is a string.\\\n",
    "        The parameter ks ist just needed for 6ECTS.\"\"\"\\\n",
    "        assert(len(X) == len(Y))\\\n",
    "        \\\n",
    "        self.data_min = np.min (X, axis = 0)\\\n",
    "        #print( \"self.data_min\",self.data_min, type(self.data_min)) # [4.3 2.2 1.  0.1] <class 'numpy.ndarray'>\\\n",
    "        self.data_max = np.max (X, axis = 0)\\\n",
    "        #print( \"self.data_max\",self.data_max, type(self.data_max)) # [7.9 4.4 6.9 2.5] <class 'numpy.ndarray'>\\\n",
    "        \\\n",
    "        X_train_normalized = (X - self.data_min) / (self.data_max - self.data_min)\\\n",
    "        #print( \"X_train_normalized\",X_train_normalized, type(X_train_normalized))# [[0.11111111 0.45454545 0.05084746 0.04166667]...\\\n",
    "        # <class 'numpy.ndarray'>\\\n",
    "        \\\n",
    "        self.X_train = X_train_normalized\\\n",
    "        self.Y_train = Y\\\n",
    "        \\\n",
    "        \\\n",
    "                        \\\n",
    "# TODO habe aus X -> X_test gemacht (auch im return)  \\\n",
    "    def predict(self, X_test, k=3, strategy='majority', best_combination=False):\\\n",
    "        # hier werden die X_test Datenpunkte eingegeben und das k festgelegt\\\n",
    "        \"\"\" Takes a list of samples X. Returns a list of predicted labels for the samples.\\\n",
    "        The parameter best_combination ist just needed for 6ECTS.\"\"\"\\\n",
    "        # dann wird eine Liste (?) mit den vorhergesagten Labels zur\\'fcckgegeben\\\n",
    "        return [self.predict_sample(x, k, strategy) for x in X_test]\\\n",
    "    \\\n",
    "    def predict_sample(self, x, k=3, strategy='majority'):\\\n",
    "        \"\"\" Predicts the label for a single sample x. \"\"\"\\\n",
    "        print(\"Neuer Punkt x\", x, type(x)) # 6.0, 2.2, 5.0, 1.5] <class 'list'>\\\n",
    "        \\\n",
    "        # Punkt normalisieren\\\n",
    "        x_normalized = (x - self.data_min) / (self.data_max - self.data_min)\\\n",
    "        ##print( \"x_normalized\",x_normalized, type(x_normalized)) # 1.) [0.47222222 0.  0.6779661  0.58333333] <class 'numpy.ndarray'> 2.)...\\\n",
    "        \\\n",
    "        number_of_rows = len(X_train)\\\n",
    "        #print(\"number_of_rows\", number_of_rows) #97\\\n",
    "        \\\n",
    "        # Distanz zu den Neighbors berechnen \\\n",
    "        neighbors = []\\\n",
    "        for i in range(number_of_rows):\\\n",
    "            #print(\"X_train[i]\",X_train[i]) # 1.) [4.7, 3.2, 1.3, 0.2], ...\\\n",
    "            #print(\"x\",x) # 1.) bei i = 0- 96:  [6.0, 2.2, 5.0, 1.5], 2.) bei i = 0- 96: ...\\\n",
    "            distance = self.dist_fun(x_normalized, self.X_train[i])\\\n",
    "            #print(\"distance\", distance) # 26.656894042629947, ...\\\n",
    "            neighbors.append((distance, Y_train[i]))\\\n",
    "        #print(\"neighbors\", neighbors) # [(1.0117773353515311, 'setosa'), (0.98...\\\n",
    "        \\\n",
    "        # sort\\\n",
    "        neighbors = sorted(neighbors)    \\\n",
    "\\\n",
    "        # Die nachsten k Nachbarn auswaehlen und in numpy array konvertieren\\\n",
    "        k_neighbors = neighbors[:k]   \\\n",
    "        k_neighbors = np.array(k_neighbors)\\\n",
    "        #print(\"k_neighbors\", k_neighbors) # 1.)['0.10133244322872142' 'versicolor'] ['0.2142601761355073' 'virginica']...\\\n",
    "\\\n",
    "        # Listen mit den unique labels erstellen und den counts (counts fuer majority)\\\n",
    "        labels = k_neighbors[:, 1]\\\n",
    "        #print(\"labels\", labels) # 1.) ['versicolor' 'virginica' 'virginica'], 2.) ...     \\\n",
    "        uniq_label, counts = np.unique(labels, return_counts=True)\\\n",
    "        #print(\"uniq_label\", uniq_label) # 1.) ['versicolor' 'virginica'], 2.)...\\\n",
    "        #print(\"counts\", counts, type(counts)) # 1.) counts [1 2] <class 'numpy.ndarray'>     \\\n",
    "        \\\n",
    "        \\\n",
    "        if strategy=='majority':  \\\n",
    "            # Eine einfache Mehrheitsabstimmung unter den Nachbarn\\\n",
    "        \\\n",
    "            ##print(\"uniq_label\", uniq_label) # 1.) ['versicolor' 'virginica'], 2.)...\\\n",
    "            ##print(\"counts\", counts, type(counts)) # 1.) counts [1 2] <class 'numpy.ndarray'>     \\\n",
    "        \\\n",
    "            pred = uniq_label[counts.argmax()]\\\n",
    "            ##print(\"pred\", pred) # 1.) virginica, 2.) ...\\\n",
    " \\\n",
    "\\\n",
    "        elif strategy == 'inverse_squared_distance':\\\n",
    "            # Jeder Nachbar wird mit dem inversen Quadrat der Distanz gewichtet.\\\n",
    "\\\n",
    "            weighted_unique_k_neighbors = []          \\\n",
    "            for i in uniq_label:\\\n",
    "                #print(\"i\", i)\\\n",
    "                weight_i = 0\\\n",
    "                for j in k_neighbors:\\\n",
    "                    #print(\"j[1]\", j[1])\\\n",
    "                    if j[1]== i:\\\n",
    "                        ##print(\"dist\",j[1], float(j[0]))\\\n",
    "                        weight_j = 1/((float(j[0])**2))\\\n",
    "                        ##print(\"weight_j\", i, weight_j)\\\n",
    "                        weight_i += weight_j\\\n",
    "                        #print(\"weight_i\", weight_i) # 1.) 97.38744495294013, 2.) ...\\\n",
    "                #print(\"weight_i\", weight_i)\\\n",
    "                weighted_unique_k_neighbors.append((i, weight_i))\\\n",
    "            ##print(\"weighted_unique_k_neighbors\", weighted_unique_k_neighbors) # [('versicolor', 97.38744495294013), ('virginica', 36.28786031018865)]\\\n",
    "           \\\n",
    "            maxi = 0\\\n",
    "            for i in weighted_unique_k_neighbors:\\\n",
    "                if i[1] > maxi:\\\n",
    "                    maxi = i[1]\\\n",
    "                    pred = i[0]\\\n",
    "\\\n",
    "            ##print(\"pred\", pred) # 1.) virginica, 2.) ...\\\n",
    "        \\\n",
    "        \\\n",
    "        elif strategy == 'inverse_avg_distance':\\\n",
    "            # Die Stimmen einer Klasse werden mit dem Inversen ihrer Durchschnittsdistanz gewichtet.\\\n",
    "            \\\n",
    "            # Inverse der Durchschnittsdistanz berechnen\\\n",
    "            dict_weighted_labels = \\{\\}\\\n",
    "            for i in uniq_label: # jedes label\\\n",
    "                #print(\"i\", i) # 1.) versicolor, 2.)virginica, 3.) ...\\\n",
    "                dist_sum = 0\\\n",
    "                label_count = 0\\\n",
    "                for j in neighbors: #jeder datenpunkt des gesamten datensatzes\\\n",
    "                    #print(\"j[1]\", j[1]) #1.) versicolor, 2.) virginica, 3.) virginica 4.)...\\\n",
    "                    if j[1]== i:\\\n",
    "                        dist_sum += (float(j[0]))\\\n",
    "                        label_count +=1\\\n",
    "                        #print(\"dist_avgj\", dist_avg) # 1.) \\\n",
    "                #print(\"i, dist_sum\", i, dist_sum)\\\n",
    "                #print(\"label_count\", label_count)\\\n",
    "                dist_avg = dist_sum/label_count\\\n",
    "                #print(\"i, dist_avg\", i, dist_avg) # 1.) versicolor 0.36592428973184443, virginica 0.5367953627062749,  2.) ...\\\n",
    "                # die Inverse ihrer Durchschnittsdistanz:\\\n",
    "                weight_dist_avg = 1/(dist_avg**2)\\\n",
    "                #print(\"i, weight_dist_avg\", i, weight_dist_avg)\\\n",
    "                dict_weighted_labels[i]=weight_dist_avg\\\n",
    "            ##print(\"dict_weighted_labels\", dict_weighted_labels)\\\n",
    "            \\\n",
    "            # Weights der Stimmen der Klassen aufsummieren\\\n",
    "            unique_k_neighbors_with_label_weight = \\{\\}\\\n",
    "            for i in uniq_label: # jedes label\\\n",
    "                #print(\"i\", i) # 1.) versicolor, 2.)virginica, 3.) ...\\\n",
    "                label_weight_i = 0\\\n",
    "                for j in k_neighbors:\\\n",
    "                    #print(\"j[1]\", j[1]) #1.) versicolor, 2.) virginica, 3.) virginica \\\n",
    "                    if j[1]== i:\\\n",
    "                        #print(\"dict_weighted_labels[i]\", dict_weighted_labels[i]) \\\n",
    "                        label_weight_i+= dict_weighted_labels[i]\\\n",
    "                        #print (\"label_weight_i in if\", i, label_weight_i)\\\n",
    "                    #print (\"label_weight_i\", i, label_weight_i)\\\n",
    "                    unique_k_neighbors_with_label_weight[i]=label_weight_i\\\n",
    "            ##print(\"unique_k_neighbors_with_label_weight\", unique_k_neighbors_with_label_weight)\\\n",
    "            \\\n",
    "            pred = max(unique_k_neighbors_with_label_weight, key = unique_k_neighbors_with_label_weight.get)\\\n",
    "            ##print(\"pred\",pred)\\\n",
    "            \\\n",
    "        \\\n",
    "        elif strategy == 'distribution':\\\n",
    "            #Eine Mehrheitsabstimmung gewichtet nach der Verteilung der Klassen\\\n",
    "            \\\n",
    "            print(\"uniq_label\", uniq_label)\\\n",
    "            # Mehrheitsverhaeltnisse berechnen\\\n",
    "            dict_distribution = \\{\\}\\\n",
    "            for i in uniq_label: # jedes label\\\n",
    "                #print(\"i\", i) # 1.) versicolor, 2.)virginica, 3.) ...\\\n",
    "                label_count = 0\\\n",
    "                for j in neighbors: #jeder datenpunkt des gesamten datensatzes\\\n",
    "                    #print(\"j[1]\", j[1]) #1.) versicolor, 2.) virginica, 3.) virginica 4.)...\\\n",
    "                    if j[1]== i:\\\n",
    "                        label_count +=1\\\n",
    "                        #print(\"label_countin if \", i, label_count) # 1.)\\\n",
    "                #print(\"label_count nach for\", i, label_count)\\\n",
    "                dict_distribution[i]=label_count/number_of_rows\\\n",
    "            print(\"dict_distribution\", dict_distribution)\\\n",
    "            \\\n",
    "            # ...\\\n",
    "            \\\n",
    "            \\\n",
    "            \\\n",
    "            \\\n",
    "            \\\n",
    "            \\\n",
    "            pred = None\\\n",
    "        \\\n",
    "        \\\n",
    "        return pred\\\n",
    "       \\\n",
    "        \\\n",
    "        \\\n",
    "clf = KNN()\\\n",
    "clf.train(X_train, Y_train)\\\n",
    "for strategy in clf.strategies:\\\n",
    "    predictions = clf.predict(X_test, strategy=strategy, k=3)\\\n",
    "# naechste Zeile ist von mir:\\\n",
    "    #print(\"predictions\",predictions , type(predictions)) # ['virginica', 'versicolor', ... <class 'list'>\\\n",
    "    print('Accuracy of strategy \\{\\}: \\{\\}'.format(strategy, accuracy(predictions, Y_test)))\\\n",
    "    labels, matrix = confusion_matrix(predictions, Y_test)\\\n",
    "    print('Confusion matrix:')\\\n",
    "    print('\\\\n'.join([str(row) for row in matrix]))\\\n",
    "    print('----------')}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
