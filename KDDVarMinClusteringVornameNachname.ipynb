{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering durch Varianzminimierung\n",
    "Implementieren Sie den Algorithmus *Clustering durch Varianzminimierung* innerhalb des jupyter-Notebooks. Nutzen Sie dafür das gegebene Grundgerüst und beachten Sie die folgenden Anforderungen:\n",
    "- Die initiale Clusterung soll auf folgende Art geschehen: Die ersten $k$ Elemente des Datensatzes werden auf die $k$ Cluster verteilt.\n",
    "Die restlichen Datenpunkte sollen zufällig den Clustern zugeordnet werden. Dann werden die initialen Zentroide berechnet.\n",
    "- Als Distanzfunktion nutzen Sie bitte die Manhattan-Distanz.\n",
    "- In jedem Iterationsschritt soll der Algorithmus über alle Instanzen gehen und jede Instanz dem nächsten Centroid zuweisen. Nachdem alle Instanzen zugeordnet wurden, sollen die Zentroide neu berechnet werden.\n",
    "- Es gibt zwei Abbruchbedingungen:\n",
    "    1. Eine maximale Anzahl von Iterationen darf nicht überschritten werden.\n",
    "    2. Unterschreitet die Änderung des Wertes\n",
    "        $${TD}^2(\\mathcal{C}) := \\sum_{i=1}^{k}{{TD}^2(C_i)} \\quad\\text{mit}\\quad {TD}^2(C_i) = \\sum_{p \\in C_i}{{dist}^2(p, \\mu_{C_i})}$$\n",
    "    zwischen zwei Iterationen ein gegebenes Minimum, dann wird keine neue Iteration mehr durchgeführt.\n",
    "    \n",
    "  Die entsprechenden Grenzen werden als Parameter übergeben. Der Wert ${TD}^2(\\mathcal{C})$ misst den Abstand aller Punkte zu ihren jeweiligen Centroiden $\\mu_{C_i}$ und ist ein Maß für die Kompaktheit des Clusterings.\n",
    "- Die Modellierung der Centroide erfolgt in der Klasse *Cluster* als Liste numerischer Werte.\n",
    "- Die Klassen können um weitere Methoden ergänzt werden.\n",
    "- Sie dürfen die Pakete numpy und random für Ihre Implementierung nutzen. Außerdem werden für die Tests die Pakete pandas und matplotlib genutzt. Verwenden Sie keine weiteren Pakete für Ihre Implementierung.\n",
    "- Beim Test auf einem geeigneten Datensatz soll ein sinnvolles Clustering entstehen.\n",
    "- Mit Hilfe des *print*-Kommandos werden Zwischenergebnisse jeder Clustering-Iteration sinnvoll geloggt.\n",
    "- Ihr Programmcode sollte sinnvoll kommentiert sein und sinnvolle Variablennamen verwenden.\n",
    "- *Hinweis*: Stellen Sie sicher, dass der Algorithmus bei jeder Ausführung ohne Fehler funktioniert. \n",
    "\n",
    "Überlegen Sie sich, warum das nur unter Berücksichtigung des Grundalgorithmus aus der Vorlesung auch mit den selben Parameterwerten nicht jedes mal der Fall sein muss und wie Sie dagegen vorgehen können.\n",
    "\n",
    "- Ihre Implementierung können Sie bis zum 28.11.2022 23:59 im Moodle abgeben.\n",
    "Sollten Sie Fragen zu den Aufgaben haben, wenden Sie sich bitte persönlich oder per E-Mail an [Maximilian Stubbemann](mailto:stubbemann@cs.uni-kassel.de).\n",
    "\n",
    "## Zusatzaufgabe für 6 ECTS:\n",
    "**Hinweis**: Bearbeiten Sie diese Aufgabe nur, falls Sie am Praktikum für 6 ECTS-Punkte teilnehmen, jedoch nicht, falls Sie am Praktikum für 3 ECTS-Punkte teilnehmen.\n",
    "\n",
    "Das Ziel des folgenden Algorithmus ist es, das Clustering durch Varianzminimierung zu verbessern, indem bessere Startcluster gewählt werden. Der Algorithmus geht dabei wie folgt vor:\n",
    "1. Es wird ein Datenpunkt zufällig (gleichverteilt) als erster Zentrumspunkt gewählt.\n",
    "2. Für jeden Datenpunkt $x$, welcher noch kein Zentroid ist, wird $D(x)$ als die Distanz zwischen x und dem nähesten Zentrumspunkt zu $x$ berechnet.\n",
    "3. Es wird ein weiterer Zentrumspunkt mit einer gewichteten Wahrscheinlickeitsverteilung gewählt, wobei der Punkt $x$ mit einer Wahrscheinlichkeit proportional zu $D(x)^2$ gewählt wird.\n",
    "4. Die Schritte 2 und 3 werden wiederholt, bis $k$ Zentrumspunkte gewählt wurden.\n",
    "5. Mit den $k$ Zentrumspunkte als Startpunkten wird dann ein Clustering durch Varianzminimierung durchgeführt.\n",
    "\n",
    "Modifizieren Sie Ihren Code so, dass beim Aufruf durch einen Parameter **init** ausgewählt werden kann, ob der optimierte Initialisierungsalgorithmus verwendet werden soll.\n",
    "\n",
    "## Tipps:\n",
    "- Zum Debugging kann es hilfreich sein, sich während der Implementierung einzelne Variablenwerte ausgeben zu lassen, insbesondere wenn Sie sich nicht sicher sind, welchen Variablentypen oder Wert Ihre Variable hat oder wenn für Sie unerklärliche Fehler auftreten. Entweder verwenden Sie zur Ausgabe einfach das *print*-Kommando oder erstellen eine Zelle, in die Sie den Variablennamen als letzte Anweisung schreiben und ausführen.\n",
    "- Neben dem Ausprobieren verschiedener Parameterwerte um ein besseres Verständnis für den Algorithmus zu bekommen, kann es auch sinnvoll sein, Ihre Implementierung mehrfach mit den selben Werten auszuführen.\n",
    "- Sie können (müssen aber nicht) einfache numpy-Operationen verwenden. Vektoren als Methodenparameter, Rückgabewerte oder Klasseneigenschaften sollen aber als normale Python-Listen dargestellt werden, *nicht* als numpy-Arrays. Aus dem Code und bei der Vorstellung Ihrer Implementierung sollte außerdem ersichtlich sein, dass Sie selbst die Berechnungen per Hand durchführen könnten. Dies gilt insbesondere für das Distanzmaß. \n",
    "- Jeglicher Python-Code im Jupyter-Notebook wird in der Reihenfolge ausgeführt, in der die Zellen ausgeführt wurden. Alle zugewiesenen Namen (z. Bsp. für Variablen, Funktionen und Klassen) bleiben im Speicher erhalten, sofern Sie nicht überschrieben wurden. Um einen *frischen* Zustand zu erhalten, in dem noch kein Code ausgeführt wurde, gehen Sie auf *Kernel -> Restart & Clear Output*. Falls für Sie unerklärliche Fehler auftreten oder Fehler, die Sie glauben schon behoben zu haben, kann ein Kernel Restart oft Erkenntnisse liefern. In vielen Fällen greifen Sie noch auf Programmcode zu, den Sie bereits aus den Zellen gelöscht haben. Stellen Sie vor der Abgabe sicher, dass Ihr Notebook auch in der Reihenfolge der Zellen von oben nach unten ohne Fehler durchläuft (Kernel -> Restart & Run All)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def manhattan_dist(x, y):\n",
    "    \"\"\" Returns the manhattan distance between vectors x and y.\n",
    "    A vector is represented as a list of numeric values. \"\"\"\n",
    "    assert(len(x) == len(y))\n",
    "    \n",
    "    # Ansatz: zip gibt eine List von 2 Elemente\n",
    "    distance = 0\n",
    "    for x_i,y_i in zip(x,y):\n",
    "        distance += abs(x_i - y_i)\n",
    "    return distance\n",
    "   \n",
    "\n",
    "class VarMinClusterer():\n",
    "    def __init__(self, dist_fun=manhattan_dist):\n",
    "        self.dist_fun = dist_fun\n",
    "        self.clusters = []\n",
    "    \n",
    "    def cluster(self,\n",
    "                X,\n",
    "                k=3,\n",
    "                max_iterations=20,\n",
    "                min_compactness_diff=0.05,\n",
    "                init=False):\n",
    "        \"\"\" Cluster the given data X.\n",
    "        Takes a list of samples X where each sample is a list of numeric values.\n",
    "        The parameter init determines, whether the optimized initialization procedure\n",
    "        shoud be used. If you are doing the task for 3 ECTS, this parameter should not\n",
    "        affect your code at all.\"\"\"\n",
    "        \n",
    "        # Basic parameter validation.\n",
    "        assert(len(X) > 0)\n",
    "        assert(len(X) >= k)\n",
    "        assert(max_iterations > 0)\n",
    "        \n",
    "        self.clusters = [Cluster() for i in range(k)]\n",
    "        \n",
    "        #1. Aufgabe ohne Optimierung\n",
    "        if init == False:\n",
    "        #initial\n",
    "            #1.erste k punte in jeweilige Cluster zuordnen\n",
    "            for i in range(k):\n",
    "                self.clusters[i].centroid = X[i]\n",
    "                self.clusters[i].elements.append(X[i])\n",
    "            #2.Die restlichen Datenpunkte sollen zufällig den Clustern zugeordnet werden. \n",
    "            for i in range(k-1,len(X)):\n",
    "                randomNumber = random.randint(0,k-1)\n",
    "                self.clusters[randomNumber].elements.append(X[i])\n",
    "                \n",
    "        if init == True:\n",
    "            #1. Es wird ein Datenpunkt zufällig (gleichverteilt) als erster Zentrumspunkt gewählt.\n",
    "            centroidListIndex = []\n",
    "            XNew = X.copy()\n",
    "            randomNumber = random.randint(0,len(X))\n",
    "            self.clusters[k-1].centroid = X[randomNumber]\n",
    "            self.clusters[k-1].elements.append(X[randomNumber])\n",
    "            XNew.pop(randomNumber)\n",
    "            centroidListIndex.append(randomNumber)\n",
    "            k -= 1\n",
    "            #Für jeden Datenpunkt 𝑥, welcher noch kein Zentroid ist, \n",
    "            #wird 𝐷(𝑥) als die Distanz zwischen x und dem nähesten Zentrumspunkt zu 𝑥 berechnet.\n",
    "            while k != 0:\n",
    "                distanceCentroidPunct = []\n",
    "                for i in range(len(XNew)):\n",
    "                    distanceCentroidPunctElementQuadrat = manhattan_dist(X[randomNumber],XNew[i]) **2\n",
    "                    distanceCentroidPunct.append(distanceCentroidPunctElementQuadrat)\n",
    "    #Es wird ein weiterer Zentrumspunkt mit einer gewichteten Wahrscheinlickeitsverteilung gewählt, \n",
    "    #wobei der Punkt 𝑥 mit einer Wahrscheinlichkeit proportional zu 𝐷(𝑥)2 gewählt wird.     \n",
    "                for i in range(len(XNew)):\n",
    "                    if distanceCentroidPunct[i] == max(distanceCentroidPunct):\n",
    "                        #print(\"max:\" + str(max(distanceCentroidPunct))\n",
    "                        self.clusters[k-1].centroid = XNew[i]\n",
    "                        self.clusters[k-1].elements.append(XNew[i])\n",
    "                        centroidListIndex.append(i)\n",
    "                        XNew.pop(i)\n",
    "                        k -= 1\n",
    "                        break\n",
    "            #elements in Cluster zu ordnen mit Zufall\n",
    "            print(centroidListIndex)\n",
    "            for i in range(len(XNew)):\n",
    "                randomNumber = random.randint(0,2)\n",
    "                #if the element is not the current center\n",
    "                self.clusters[randomNumber].elements.append(XNew[i])\n",
    "                 \n",
    "        #berechen Algothmus von Vorlesung\n",
    "        while max_iterations != 0 or min_compactness_diff >= 0.05:\n",
    "            centroidenList = []\n",
    "            #μC0 = μC;\n",
    "            compactnessOldClusters = 0\n",
    "            for cluster in self.clusters:\n",
    "                centroidenList.append(cluster.centroid)\n",
    "                 # old elements in jede Cluster leeren\n",
    "                cluster.elements = []\n",
    "                #calculate compactness for the old cluster \n",
    "                compactnessOldClusters = compactnessOldClusters + cluster.compactness()\n",
    "                \n",
    "            #jede Punkt eine neue Cluster zuordnen\n",
    "            for point in X:\n",
    "                newClusterCalculate = []\n",
    "                #jede Punkte in Cluster , berechnen mal die manhattan_dist, werden der Punkte zu der Kleinste Wert geordnet.\n",
    "                for centroide in centroidenList:\n",
    "                    newClusterCalculate.append(manhattan_dist(point, centroide))\n",
    "                minDistance = min(newClusterCalculate)\n",
    "                min_index=newClusterCalculate.index(minDistance)\n",
    "                self.clusters[min_index].elements.append(point)\n",
    "                \n",
    "            #td fuer ganze clusters berechnen\n",
    "            compactnessNewClusters = 0\n",
    "            for cluster in self.clusters:\n",
    "                cluster.calculateCentroide()\n",
    "                compactnessNewClusters = compactnessNewClusters + cluster.compactness()\n",
    "        \n",
    "            max_iterations -=1\n",
    "            min_compactness_diff = abs(compactnessOldClusters-compactnessNewClusters)\n",
    "                \n",
    "        return self.clusters\n",
    "\n",
    "class Cluster():\n",
    "    def __init__(self):\n",
    "        self.elements = []\n",
    "        self.centroid = []\n",
    "    \n",
    "    def compactness(self, dist_fun=manhattan_dist):\n",
    "        # TODO\n",
    "        #Die entsprechenden Grenzen werden als Parameter übergeben. \n",
    "        sum = 0\n",
    "        for x in self.elements:\n",
    "          sum = sum + manhattan_dist(self.centroid,x)**2\n",
    "        return sum\n",
    "    \n",
    "    def calculateCentroide(self,dist_fun=manhattan_dist):\n",
    "        elementsNP = np.array(self.elements)\n",
    "        #Mittelwert fur alle Elements\n",
    "        center = np.mean(elementsNP, axis=0)\n",
    "        #die nahliegendeste Punkt zu suchen\n",
    "        newCenterTempList = []\n",
    "        for point in self.elements:\n",
    "            newCenterTempList.append(manhattan_dist(center,point))\n",
    "        minDistance = min(newCenterTempList)\n",
    "        min_index=newCenterTempList.index(minDistance)\n",
    "        self.centroid = self.elements[min_index]\n",
    "        return self.centroid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausführung des Clusterings\n",
    "Hier kann der implementierte Algorithmus getestet werden. Bitte an den vorhandenen Zellen nichts ändern. Sie können aber weitere Zellen mit eigenem Code hinzufügen oder andere Parameterwerte ausprobieren (die Sie in der Abgabe dann wieder auf die ursprünglichen Werte ändern).\n",
    "\n",
    "Um den Code auszuführen, müssen die Bibliotheken *pandas*, *matplotlib* und eventuell weitere Abhängigkeiten installiert sein. Diese sind in der Anaconda-Distribution bereits enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris-dataset. Remove the class-attribute.\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"iris.csv\")\n",
    "del data[\"species\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering(clusters, x_dim=0, y_dim=3):\n",
    "    \"\"\"Show a scatterplot of the given clusters and contained data-points.\n",
    "    Points from the same cluster will have the same color.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure()\n",
    "    for cluster in clusters:\n",
    "        elems = np.array(cluster.elements)\n",
    "        plt.scatter(elems[:, x_dim], elems[:, y_dim])\n",
    "        ctr = cluster.centroid\n",
    "        plt.plot(ctr[x_dim], ctr[y_dim], \"X\", c=\"black\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a clustering with k=3 and plot the result with the optimized initialization routine.\n",
    "# This code should run and (always) show a correct result, once the classes have been implemented.\n",
    "alg = VarMinClusterer()\n",
    "clusters = alg.cluster(data.values.tolist(), k=3, init=True)\n",
    "plot_clustering(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a clustering with k=3 and plot the result.\n",
    "# This code should run and (always) show a correct result, once the classes have been implemented.\n",
    "alg = VarMinClusterer()\n",
    "clusters = alg.cluster(data.values.tolist(), k=3, init=False)\n",
    "plot_clustering(clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
